<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>多模态大模型 on DIZS' Blog</title><link>https://blackdzs.github.io/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 多模态大模型 on DIZS' Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 04 Nov 2024 10:44:38 +0800</lastBuildDate><atom:link href="https://blackdzs.github.io/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>视觉语言模型（VLM）对比研究</title><link>https://blackdzs.github.io/p/%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E5%AF%B9%E6%AF%94%E7%A0%94%E7%A9%B6/</link><pubDate>Mon, 04 Nov 2024 10:44:38 +0800</pubDate><guid>https://blackdzs.github.io/p/%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E5%AF%B9%E6%AF%94%E7%A0%94%E7%A9%B6/</guid><description>&lt;h1 id="介绍">介绍
&lt;/h1>&lt;h1 id="架构">架构
&lt;/h1></description></item><item><title>微调视觉语言模型（VLM）注意点</title><link>https://blackdzs.github.io/p/%E5%BE%AE%E8%B0%83%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E6%B3%A8%E6%84%8F%E7%82%B9/</link><pubDate>Fri, 01 Nov 2024 16:05:43 +0800</pubDate><guid>https://blackdzs.github.io/p/%E5%BE%AE%E8%B0%83%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E6%B3%A8%E6%84%8F%E7%82%B9/</guid><description>&lt;p>在微调视觉语言模型（VLM）时，有几个关键的注意点需要考虑，以确保模型的有效性和性能：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>数据质量与数量&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>确保训练数据的质量与期望输出要一致，包括内容和格式。垃圾数据无法训练出好的模型。&lt;/li>
&lt;li>针对模型难度，数据量需求不同：普通业务一般需要千条数据，复杂任务可能需要1-2万条数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>数据生成与构建&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>可以通过手工标注和GPT改写生成高质量的业务数据。&lt;/li>
&lt;li>对于输出格式不稳定的情况，可以少量的数据（几十到上百条）进行针对性改写。&lt;/li>
&lt;li>使用自然图像生成的caption数据和instruction数据，丰富模型的训练数据来源。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>训练策略&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>初步使用较小的模型（2B~7B），进行高学习率（1e-5）和适当的epoch（如10轮）训练，确保基础性能。&lt;/li>
&lt;li>测试集评估时，优先在训练集上验证效果，以排除数据质量问题。&lt;/li>
&lt;li>在训练提升效果前，分阶段使用质量较差的大量数据，后期引入高质量的小批量数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>超参数调节&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>定期根据训练集上的反馈调整超参数，如训练轮次、学习率、batch_size等。&lt;/li>
&lt;li>在训练结束后进行效果评估，避免因过拟合导致性能下降。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>多样性与通用能力&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>在引入通用数据时，起始比例建议从10:1开始，根据效果进行调整。&lt;/li>
&lt;li>将通用的caption数据与具体的instruction数据进行结合，丰富模型对视觉信息的理解。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>训练阶段与流程&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>训练可以分为多个阶段，对不同任务类型的数据进行先后训练，确保每个子任务的效果都良好。&lt;/li>
&lt;li>注意训练过程中保持常见的高质量刺激与低质量数据的适当比例。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>持续监控与评估&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>在训练过程中持续监控模型的表现，包括损失曲线和泛化能力，避免模型过早收敛导致性能下降。&lt;/li>
&lt;li>若发现泛化性能不足，考虑增加多样的输入形式以刺激模型更好地学习。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>总结来说，微调VLM应重视数据的质量与构建、合理的训练策略、超参数的动态调整，以及适时引入通用数据，以达到最佳的模型性能。&lt;/p></description></item></channel></rss>