[{"content":"介绍 架构 ","date":"2024-11-04T10:44:38+08:00","permalink":"https://blackdzs.github.io/p/%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E5%AF%B9%E6%AF%94%E7%A0%94%E7%A9%B6/","title":"视觉语言模型（VLM）对比研究"},{"content":"在微调视觉语言模型（VLM）时，有几个关键的注意点需要考虑，以确保模型的有效性和性能：\n数据质量与数量：\n确保训练数据的质量与期望输出要一致，包括内容和格式。垃圾数据无法训练出好的模型。 针对模型难度，数据量需求不同：普通业务一般需要千条数据，复杂任务可能需要1-2万条数据。 数据生成与构建：\n可以通过手工标注和GPT改写生成高质量的业务数据。 对于输出格式不稳定的情况，可以少量的数据（几十到上百条）进行针对性改写。 使用自然图像生成的caption数据和instruction数据，丰富模型的训练数据来源。 训练策略：\n初步使用较小的模型（2B~7B），进行高学习率（1e-5）和适当的epoch（如10轮）训练，确保基础性能。 测试集评估时，优先在训练集上验证效果，以排除数据质量问题。 在训练提升效果前，分阶段使用质量较差的大量数据，后期引入高质量的小批量数据。 超参数调节：\n定期根据训练集上的反馈调整超参数，如训练轮次、学习率、batch_size等。 在训练结束后进行效果评估，避免因过拟合导致性能下降。 多样性与通用能力：\n在引入通用数据时，起始比例建议从10:1开始，根据效果进行调整。 将通用的caption数据与具体的instruction数据进行结合，丰富模型对视觉信息的理解。 训练阶段与流程：\n训练可以分为多个阶段，对不同任务类型的数据进行先后训练，确保每个子任务的效果都良好。 注意训练过程中保持常见的高质量刺激与低质量数据的适当比例。 持续监控与评估：\n在训练过程中持续监控模型的表现，包括损失曲线和泛化能力，避免模型过早收敛导致性能下降。 若发现泛化性能不足，考虑增加多样的输入形式以刺激模型更好地学习。 总结来说，微调VLM应重视数据的质量与构建、合理的训练策略、超参数的动态调整，以及适时引入通用数据，以达到最佳的模型性能。\n","date":"2024-11-01T16:05:43+08:00","permalink":"https://blackdzs.github.io/p/%E5%BE%AE%E8%B0%83%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8Bvlm%E6%B3%A8%E6%84%8F%E7%82%B9/","title":"微调视觉语言模型（VLM）注意点"},{"content":"补充中\u0026hellip;\n","date":"2024-10-31T11:59:12+08:00","permalink":"https://blackdzs.github.io/p/rag%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97%E4%B8%89%E5%A6%82%E4%BD%95%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE/","title":"RAG应用开发指南（三）：如何自动生成高质量的问答数据"},{"content":"TF-IDF 算法研究文档 1. 背景 TF-IDF（Term Frequency-Inverse Document Frequency） 是一种经典的文本特征提取算法，广泛应用于信息检索、文本分类和推荐系统等场景。该算法能够衡量词语在单个文档中的重要性，并有效抑制高频常见词（如“的”“是”等）的干扰，从而更准确地表征文档内容。此外，TF-IDF 在基于大模型的 RAG（Retrieval-Augmented Generation）系统 中也被用于提升检索过程的召回率，帮助更全面地获取相关信息。\n2. 算法原理 TF-IDF 通过两个重要指标来度量词语的重要性：\nTF（词频，Term Frequency）\n词频指某个词在一篇文档中出现的频率。假设有一个文档 \\(d\\)，词语 \\(t\\) 在该文档中的出现次数为 \\(f(t, d)\\)，则该词的 TF 定义为：\n\\[ TF(t, d) = \\frac{f(t, d)}{n(d)} \\] 其中，\\(n(d)\\) 表示文档 \\(d\\) 中的总词数。\nIDF（逆文档频率，Inverse Document Frequency）\nIDF 用来衡量一个词语在整个语料库中的重要性。如果一个词语在很多文档中出现，那么它的重要性应被降低。假设语料库中有 \\(N\\) 篇文档，其中包含词 \\(t\\) 的文档数为 \\(n_t\\)。IDF 的定义为：\n\\[ IDF(t) = \\log \\frac{N}{1 + n_t} \\] 这里加 1 是为了避免分母为 0 的情况。\nTF-IDF 计算公式\nTF-IDF 将 TF 和 IDF 相乘，得到词语 \\(t\\) 在文档 \\(d\\) 中的重要性分数：\n\\[ TF\\text{-}IDF(t, d) = TF(t, d) \\times IDF(t) \\] 3. 示例 假设我们有如下语料库，共 3 篇文档：\n文档 1：机器学习 是 人工智能 的 分支\n文档 2：机器学习 包括 深度学习 和 传统算法\n文档 3：深度学习 是 机器学习 的 重要 领域\n词频（TF）计算\n对“机器学习”进行计算：\n文档 1：“机器学习”出现 1 次，总词数 6，TF = 1/6 文档 2：“机器学习”出现 1 次，总词数 6，TF = 1/6 文档 3：“机器学习”出现 1 次，总词数 7，TF = 1/7 逆文档频率（IDF）计算\n在 3 篇文档中，“机器学习”出现在 3 篇，因此：\n\\[ IDF(\\text{机器学习}) = \\log \\frac{3}{1 + 3} = \\log \\frac{3}{4} \\approx -0.125 \\] TF-IDF 计算\n以“机器学习”为例：\n文档 1：TF-IDF = \\(1/6 \\times -0.125 = -0.0208\\) 文档 2：TF-IDF = \\(1/6 \\times -0.125 = -0.0208\\) 文档 3：TF-IDF = \\(1/7 \\times -0.125 \\approx -0.0179\\) 结果分析\n由于“机器学习”在所有文档中均出现，因此其 IDF 值较低，意味着它的辨识度不高。在实践中，诸如“的”“是”等高频词语往往会被 TF-IDF 削弱，从而凸显出更具区分性的词汇。\n4. 应用场景 搜索引擎\nTF-IDF 可用于根据查询词对文档的重要性进行排序，从而提高搜索结果的相关性。\n文本分类\n使用 TF-IDF 提取文档的特征向量，输入到机器学习模型（如 SVM、朴素贝叶斯等）进行分类。\n推荐系统\n在内容推荐中，基于 TF-IDF 计算用户对不同文档的兴趣度，推荐个性化内容。\n关键词提取\n自动从文本中提取重要关键词，帮助摘要生成或标签推荐。\n5. 优缺点 优点：\n简单易实现 计算效率高，适合大规模文本处理 能有效衡量词汇在文档中的重要性 缺点：\n无法捕捉词语之间的语义关系 对长文档不够鲁棒，容易偏向高频词 静态权重无法适应动态的语料库更新 6. 结论 TF-IDF 作为一种经典的文本分析算法，尽管已经存在多年，但在信息检索等领域依然具有广泛的应用价值。它通过结合词频和逆文档频率，有效地筛选出具有辨识度的词汇。然而，随着深度学习和预训练模型的发展，像 BERT、GPT 等模型逐渐成为文本处理的主流。尽管如此，TF-IDF 由于其简单高效的特点，在某些场景中仍是一个不可替代的工具。\n7. 代码实现示例（Python） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from sklearn.feature_extraction.text import TfidfVectorizer # 语料库 corpus = [ \u0026#34;机器学习 是 人工智能 的 分支\u0026#34;, \u0026#34;机器学习 包括 深度学习 和 传统算法\u0026#34;, \u0026#34;深度学习 是 机器学习 的 重要 领域\u0026#34; ] # 初始化 TF-IDF 向量化器 vectorizer = TfidfVectorizer() X = vectorizer.fit_transform(corpus) # 输出 TF-IDF 权重矩阵 print(\u0026#34;词汇表：\u0026#34;, vectorizer.get_feature_names_out()) print(\u0026#34;TF-IDF 权重矩阵：\\n\u0026#34;, X.toarray()) 输出示例 1 2 3 4 5 6 7 8 词汇表： [\u0026#39;人工智能\u0026#39; \u0026#39;传统算法\u0026#39; \u0026#39;分支\u0026#39; \u0026#39;包括\u0026#39; \u0026#39;机器学习\u0026#39; \u0026#39;深度学习\u0026#39; \u0026#39;重要\u0026#39; \u0026#39;领域\u0026#39;] TF-IDF 权重矩阵： [[0.65249088 0. 0.65249088 0. 0.38537163 0. 0. 0. ] [0. 0.5844829 0. 0.5844829 0.34520502 0.44451431 0. 0. ] [0. 0. 0. 0. 0.34520502 0.44451431 0.5844829 0.5844829 ]] 8. 参考文献 Salton, G., \u0026amp; Buckley, C. (1988). Term-weighting approaches in automatic text retrieval. Information Processing \u0026amp; Management, 24(5), 513–523. Manning, C. D., Raghavan, P., \u0026amp; Schütze, H. (2008). Introduction to Information Retrieval. Cambridge University Press. ","date":"2024-10-15T20:40:03+08:00","permalink":"https://blackdzs.github.io/p/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90tf-idf%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%BA%94%E7%94%A8%E5%8F%8Apython%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/","title":"深入解析TF-IDF算法：原理、应用及Python实现详解"},{"content":"随着大模型的爆火，在业务场景中我们听到AI相关的需求越来越多，这时候我们就要面临一个问题，如何选择一个AI框架，让AI需求快速实现进行落地验证？本文将对当前主流的AI应用开发框架进行比较探讨。在深入讨论框架之前，我们需要先理解AI应用如何与现有业务进行整合，如数字员工、AI客服及AI助理等等。由于大模型在训练和部署阶段对硬件资源的要求较高，因此模型与应用通常会实现分离，Model as a Service（MaaS）成为新的AI开发范式。因此，在AI应用开发过程中，也会遵循这一范式，即将AI应用视为一个独立的服务，为下游各种各样的业务提供AI能力。\nAI应用开发框架 简单来说，目前AI应用开发框架的主流发展方向分为重代码开发和低代码开发平台。其中，重代码开发的代表性工具有：\nLangchain: 92.9k star LlamaIndex: 35.8k star Haystack: 16.9k star 其中Langchain的社区和功能性最完善，虽然其抽象程度比较高，定制化难度比较大，但是可以作为快速构建AI应用并进行验证的工具。LlamaIndex 更加侧重于RAG应用开发，注重检索任务。Haystack简单易懂，抽象程度比Langchain低，因此定制化难度会低一些，但是目前社区的支持还比较少。\n低代码开发平台的代表性工具有：\nDify: 46.8k star Flowise: 30.2k star Langflow: 30k star 这三个低代码平台都是通过托拉拽的方式进行AI应用开发，同时提供前端页面访问和API访问，因此可以快速与现有的业务场景进行集成。其中Dify上手难度最小，但是涉及到定制化或者集成自定义的一些功能时难度最高；\nFlowise是基于langchainjs和LLamaIndexTS进行开发，相当于是对Langchain和LlamaIndex进行封装，并提供一个低代码平台进行Langchian或者LlamaIndex模块进行组合；\nLangflow是对Langchain进行封装，形成低代码开发平台，其定制化程度非常高，支持在线实时更改节点代码实时生效。\nAI应用开发低代码平台对比 结论 在AI应用开发的初期，建议先选择Langchain和Dify作为首选工具，以便快速构建AI应用并进行落地验证。当面对某些实际需求时，如果这些框架无法满足，则可以考虑其他框架的实施方案。一方面，当前大模型及AI应用开发尚处于快速迭代阶段，各框架对新功能的支持程度存在差异，因此了解多个框架的特点是非常必要的。另一方面，AI框架和工具的同质化现象较为严重，从一个框架切换到另一个框架相对容易，因此不必过于担忧切换框架的成本问题。\n","date":"2024-09-30T10:25:23+08:00","permalink":"https://blackdzs.github.io/p/ai%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94/","title":"AI应用开发框架对比"},{"content":"介绍 在深入解析RAG原理与实现一文中，我们探讨了如何构建RAG应用。然而，在成功构建RAG应用后，新的挑战随之而来：如何评估其性能？我们需要什么样的量化指标来进行有效的评估？\nRAG评估 评估指标 在RAG流程中，主要包括三个核心部分：问题（Query）、检索到的文档（Context）以及模型生成的答案（Answer）。在评估过程中，我们还需要真实答案（Ground Truth）作为基准。在RAG应用中，我们关注两个关键点：其一是检索到的文档（Context），其二是基于检索到的文档所生成的答案（Answer）。下图1展示了这两个部分设置的评估指标，其中左侧列出了与Answer相关的指标，右侧则呈现了与Context相关的指标。指标计算方法可以参考RAGAS Metrics\nContext\nContext Precision: 根据Context和Ground Truth计算检索到的Context准确率 Context Recall: 根据Context和Ground Truth计算检索到的Context召回率 Context Entities Recall: 根据Context和Ground Truth计算检索到的Context 中Entities的召回率 Answer\nAnswer Faithfulness: 根据Context和Answer计算Answer是否来源于Context Answer Semantic Similarity: 根据Ground Truth和Answer计算Answer与Ground Truth的语义相似性(使用Embedding向量计算) Answer Correctness: 根据Ground Truth和Answer计算Answer准确率(使用LLM判断) 通过以上评估指标，我们能够更全面地评价RAG系统的性能。\n图 1. RAG 评估指标 计算方法 尽管大型语言模型（LLM）的上下文长度已显著增加，能够将整个文档甚至文本语料库纳入上下文窗口，但在实际应用中，这种做法往往效率低下，容易分散模型的注意力，同时也会增加推理延迟和成本。对于任何特定查询，仅有少量的文本可能具有相关性，但在每次推理时，上下文窗口中的所有token都需被处理。理想情况下，LLM 应该只处理与查询相关的token。因此，在检索增强生成（RAG）应用中，检索过程的主要目标便是精准识别并提取与给定查询相关的token。\nContext Precison Context Precision（上下文精度）是信息检索和问答系统中用来评估检索结果质量的重要指标之一。在检索过程中，系统可能会返回多个与用户查询相关的文档，这些文档的内容可能会对生成答案产生不同程度的影响。Context Precision的核心在于衡量在检索到的所有相关文档中，有多少文档实际上对生成用户需要的答案是有帮助的。\n\\[ Context\\:Precision = \\frac{有用的文档数量}{相关文档数量} \\] 相关文档数量 ：指检索系统返回的所有相关文档的总数。 有用文档数量 ：指在这些相关文档中，能够为生成正确答案提供有效信息的文档数量。 那么如何衡量文档对于答案生成是否有用呢？传统的NLP方法中可以使用EM算法，或者计算文档和答案之间词级匹配，这些方法仅计算词级别的重叠，忽略了语义上的近似表达。例如，“机器学习用于预测”与“模型被训练来预测”语义相近，但词汇不完全匹配，导致得分偏低。对于开放性问答任务，上下文和答案可能有多种合理表述，传统的机器学习方法无法处理这种问题。同时如果文档包含大量与问题无关的内容，只是偶尔提到了一些相关词汇，会导致误判。为了解决这些问题，可以使用基于大模型的计算方法，依赖于大模型的上下文学习以及推理能力进行判断文档对于答案生成是否有用，如：\n1 2 3 问题：什么是机器学习？ 文档：机器学习是一种通过数据训练模型的技术，用于模式识别和预测。 提示：这个文档是否足以回答问题？请在1-5之间打分，并解释原因。 下面是对于衡量文档对于答案生成是否有用的Prompt示例，其中包含指令，格式化输出，示例和输入，通过这种设计方式可以让大模型生成格式化的评估结果。\n图 2. Context Precision Prompt 因此Context Precision的计算过程如图3所示，首先是根据用户问题检索相关文档，对于每个文档使用图2中的Prompt输入到大模型中，获取大模型对于文档是否有用的判断，最终根据有用的文档数量计算Context Precision\n图 3. Context Precision 计算过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 import json from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate llm = ChatOpenAI( api_key=\u0026#34;your_api_key\u0026#34;, model=\u0026#34;gpt-4o-mini\u0026#34; ) PROMPT = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \u0026#34;1\u0026#34; if useful and \u0026#34;0\u0026#34; if not with json output. The output should be a well-formatted JSON instance that conforms to the JSON schema below. As an example, for the schema {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: {{\u0026#34;title\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;a list of strings\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {{\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}}}}, \u0026#34;required\u0026#34;: [\u0026#34;foo\u0026#34;]}} the object {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}} is a well-formatted instance of the schema. The object {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}}}} is not well-formatted. Here is the output JSON schema: {OutputSchema} Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```). Examples: question: \u0026#34;What can you tell me about Albert Einstein?\u0026#34; context: \u0026#34;Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been called \u0026#39;the world\u0026#39;s most famous equation\u0026#39;. He received the 1921 Nobel Prize in Physics \u0026#39;for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\u0026#39;, a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\u0026#34; answer: \u0026#34;Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics.\u0026#34; verification: {{ \u0026#34;reason\u0026#34;: \u0026#34;The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein\u0026#39;s life and contributions, which are reflected in the answer.\u0026#34;, \u0026#34;verdict\u0026#34;: 1 }} question: \u0026#34;who won 2020 icc world cup?\u0026#34; context: \u0026#34;The 2022 ICC Men\u0026#39;s T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men\u0026#39;s T20 World Cup title.\u0026#34; answer: \u0026#34;England\u0026#34; verification: {{ \u0026#34;reason\u0026#34;: \u0026#34;the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.\u0026#34;, \u0026#34;verdict\u0026#34;: 1 }} question: \u0026#34;What is the tallest mountain in the world?\u0026#34; context: \u0026#34;The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.\u0026#34; answer: \u0026#34;Mount Everest.\u0026#34; verification: {{ \u0026#34;reason\u0026#34;: \u0026#34;the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world\u0026#39;s tallest mountain.\u0026#34;, \u0026#34;verdict\u0026#34;: 0 }} Your actual task: \u0026#34;\u0026#34;\u0026#34; ), ( \u0026#34;human\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your actual task: question: \u0026#34;{Query}\u0026#34; context: \u0026#34;{Context}\u0026#34; answer: \u0026#34;{Answer}\u0026#34; verification: \u0026#34;\u0026#34;\u0026#34; ) ] ) def get_v(query, context, answer): output_schema = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;description\u0026#34;: \u0026#34;Answer for the verification task wether the context was useful.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;reason\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Reason\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Reason for verification\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;verdict\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Verdict\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Binary (0/1) verdict of verification\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;reason\u0026#34;, \u0026#34;verdict\u0026#34;]}\u0026#34;\u0026#34;\u0026#34; chain = PROMPT | llm result = chain.invoke( { \u0026#34;OutputSchema\u0026#34;: output_schema, \u0026#34;Query\u0026#34;: query, \u0026#34;Context\u0026#34;: context, \u0026#34;Answer\u0026#34;: answer } ) content = result.content if content.startswith(\u0026#34;```json\u0026#34;): content = content.replace(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;) if content.endswith(\u0026#34;```\u0026#34;): content = content.replace(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;) try: content = json.loads(content) verdict = content[\u0026#34;verdict\u0026#34;] except: verdict = None print(content) return verdict verdicts = [] query = \u0026#34;艾菲尔铁塔在哪里\u0026#34; contexts = [ \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物\u0026#34;, \u0026#34;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#34; ] answer = \u0026#34;艾菲尔铁塔位于巴黎\u0026#34; for context in contexts: verdicts.append(get_v(query=query, context=context, answer=answer)) print(\u0026#34;Context Precision: \u0026#34;, sum(verdicts) / len(verdicts)) 1 2 3 {\u0026#39;reason\u0026#39;: \u0026#39;提供的上下文直接描述了艾菲尔铁塔的位置，明确说明它位于法国巴黎，因此上下文对于得出答案是非常有用的。\u0026#39;, \u0026#39;verdict\u0026#39;: 1} {\u0026#39;reason\u0026#39;: \u0026#39;上下文提到艾菲尔铁塔的建设和设计师，但没有直接说明它的位置，因此在回答中提到艾菲尔铁塔位于巴黎的内容未得到上下文的支持。\u0026#39;, \u0026#39;verdict\u0026#39;: 0} Context Precision: 0.5 Context Recall Context Recall（上下文召回率） 是一种用于评估信息检索系统中检索结果覆盖程度的重要指标。它反映了系统在上下文中检索到的内容与预期信息（即 Ground Truth）之间的匹配程度。在开放问答系统中，Ground Truth 表示预期答案的完整内容或参考答案。Context Recall 的计算流程是通过将 Ground Truth 分解为多个独立的观点（statement），并判断这些句子是否能在检索到的上下文中找到对应内容。\nContext Recall 的计算公式如下：\n\\[ Context\\:Recall = \\frac{上下文中存在的正确观点数量}{Ground Truth 的所有观点数量} \\] 上下文中存在的正确观点数量：在给定上下文中能够找到支持的观点的数量。 Ground Truth 的所有观点数量：答案中涉及的所有观点的数量。 Prompt 示例\n图 4. Context Recall Prompt Context Recall 计算流程\n1 2 3 1. 检索上下文：从信息源中获取相关上下文。 2. 大模型判断：将Query, Context, Ground Truth 填入 Prompt 交给大模型，判断是否在上下文中找到匹配的观点(statement)。 3. 计算 Context Recall：根据分类为1的statement和总statement计算召回率。 下图展示了 Context Recall 的计算过程：\n图 5. Context Recall 计算过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 import json from pprint import pprint from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate llm = ChatOpenAI( api_key=\u0026#34;your_api_key\u0026#34;, model=\u0026#34;gpt-4o-mini\u0026#34; ) PROMPT = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Given a context, and an answer, analyze each sentence in the answer and classify if the sentence can be attributed to the given context or not. Use only \u0026#39;Yes\u0026#39; (1) or \u0026#39;No\u0026#39; (0) as a binary classification. Output json with reason. The output should be a well-formatted JSON instance that conforms to the JSON schema below. As an example, for the schema {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: {{\u0026#34;title\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;a list of strings\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {{\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}}}}, \u0026#34;required\u0026#34;: [\u0026#34;foo\u0026#34;]}} the object {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}} is a well-formatted instance of the schema. The object {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}}}} is not well-formatted. Here is the output JSON schema: {OutputSchema} Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```). Examples: question: \u0026#34;What can you tell me about albert Albert Einstein?\u0026#34; context: \u0026#34;Albert Einstein (14 March 1879 - 18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass-energy equivalence formula E = mc2, which arises from relativity theory, has been called \\\u0026#39;the world\\\u0026#39;s most famous equation\\\u0026#39;. He received the 1921 Nobel Prize in Physics \\\u0026#39;for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\\\u0026#39;, a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.\u0026#34; answer: \u0026#34;Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895\u0026#34; classification: [{{\u0026#34;statement\u0026#34;: \u0026#34;Albert Einstein, born on 14 March 1879, was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time.\u0026#34;, \u0026#34;attributed\u0026#34;: 1, \u0026#34;reason\u0026#34;: \u0026#34;The date of birth of Einstein is mentioned clearly in the context.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;He received the 1921 Nobel Prize in Physics for his services to theoretical physics.\u0026#34;, \u0026#34;attributed\u0026#34;: 1, \u0026#34;reason\u0026#34;: \u0026#34;The exact sentence is present in the given context.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;He published 4 papers in 1905.\u0026#34;, \u0026#34;attributed\u0026#34;: 0, \u0026#34;reason\u0026#34;: \u0026#34;There is no mention about papers he wrote in the given context.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;Einstein moved to Switzerland in 1895.\u0026#34;, \u0026#34;attributed\u0026#34;: 0, \u0026#34;reason\u0026#34;: \u0026#34;There is no supporting evidence for this in the given context.\u0026#34;}}] question: \u0026#34;who won 2020 icc world cup?\u0026#34; context: \u0026#34;The 2022 ICC Men\\\u0026#39;s T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men\\\u0026#39;s T20 World Cup title.\u0026#34;\\nanswer: \u0026#34;England\u0026#34; classification: [{{\u0026#34;statement\u0026#34;: \u0026#34;England won the 2022 ICC Men\\\u0026#39;s T20 World Cup.\u0026#34;, \u0026#34;attributed\u0026#34;: 1, \u0026#34;reason\u0026#34;: \u0026#34;From context it is clear that England defeated Pakistan to win the World Cup.\u0026#34;}}] question: \u0026#34;What is the primary fuel for the Sun?\u0026#34; context: \u0026#34;NULL\u0026#34; answer: \u0026#34;Hydrogen\u0026#34; classification: [{{\u0026#34;statement\u0026#34;: \u0026#34;The Sun\\\u0026#39;s primary fuel is hydrogen.\u0026#34;, \u0026#34;attributed\u0026#34;: 0, \u0026#34;reason\u0026#34;: \u0026#34;The context contains no information\u0026#34;}}] Your actual task: \u0026#34;\u0026#34;\u0026#34; ), ( \u0026#34;human\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your actual task: question: \u0026#34;{Query}\u0026#34; context: \u0026#34;{Context}\u0026#34; answer: \u0026#34;{Answer}\u0026#34; classification: \u0026#34;\u0026#34;\u0026#34; ) ] ) def get_v(query, context, answer): output_schema = \u0026#34;\u0026#34;\u0026#34; {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;$ref\u0026#34;: \u0026#34;#/definitions/ContextRecallClassificationAnswer\u0026#34;}, \u0026#34;definitions\u0026#34;: {\u0026#34;ContextRecallClassificationAnswer\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;ContextRecallClassificationAnswer\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;statement\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Statement\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;attributed\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Attributed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;reason\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Reason\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;statement\u0026#34;, \u0026#34;attributed\u0026#34;, \u0026#34;reason\u0026#34;]}}} \u0026#34;\u0026#34;\u0026#34; chain = PROMPT | llm result = chain.invoke( { \u0026#34;OutputSchema\u0026#34;: output_schema, \u0026#34;Query\u0026#34;: query, \u0026#34;Context\u0026#34;: context, \u0026#34;Answer\u0026#34;: answer } ) content = result.content if content.startswith(\u0026#34;```json\u0026#34;): content = content.replace(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;) if content.endswith(\u0026#34;```\u0026#34;): content = content.replace(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;) try: content = json.loads(content) except: # verdict = None pass return content classes = [] query = \u0026#34;艾菲尔铁塔在哪里\u0026#34; contexts = [ \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物\u0026#34;, \u0026#34;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#34; ] answer = \u0026#34;\u0026#34;\u0026#34; 埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] （ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物。正式地址为Rue Anatole-France 5号。 埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观[4]，是法国参观人数第二多的文化景点。1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。[5] 埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现，其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。 \u0026#34;\u0026#34;\u0026#34; result = get_v(query, \u0026#34;.\u0026#34;.join(contexts), answer) pprint(result[:3]) for res in result: classes.append(res[\u0026#34;attributed\u0026#34;]) print(\u0026#34;Context Recall: \u0026#34;, sum(classes) / len(classes)) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 [{\u0026#39;attributed\u0026#39;: 1, \u0026#39;reason\u0026#39;: \u0026#39;This statement is directly supported by the context, which \u0026#39; \u0026#34;describes the Eiffel Tower\u0026#39;s location and significance.\u0026#34;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] \u0026#39; \u0026#39;（ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一，巴黎城市地标之一，巴黎最高建筑物。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;The context does not mention this specific address.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;正式地址为Rue Anatole-France 5号。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 1, \u0026#39;reason\u0026#39;: \u0026#39;This information is directly stated in the context.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#34;While the context discusses the Eiffel Tower\u0026#39;s significance, it \u0026#34; \u0026#39;does not specifically refer to it as a technological masterpiece \u0026#39; \u0026#39;or the most visited paid monument.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;The context does not provide specific visitor statistics or \u0026#39; \u0026#39;ranking.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;这个为了世界博览会而落成的金属建筑，2011年约有698万人参观，是法国参观人数第二多的文化景点。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;The context does not mention the inclusion in engineering history \u0026#39; \u0026#39;landmarks or UNESCO World Heritage status.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;The context does not provide specific height or duration of being \u0026#39; \u0026#39;the tallest man-made structure.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;The context does not mention the installation of antennas or \u0026#39; \u0026#39;height increases.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;铁塔的总高度曾通过安装天线而多次提高。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;There is no mention of antennas being used for scientific \u0026#39; \u0026#39;experiments or broadcasting.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。\u0026#39;}] Context Recall: 0.2222222222222222 ❯ python scripts/context_recall.py [{\u0026#39;attributed\u0026#39;: 1, \u0026#39;reason\u0026#39;: \u0026#39;该句描述了埃菲尔铁塔的位置和其重要性，与上下文一致。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] \u0026#39; \u0026#39;（ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一，巴黎城市地标之一，巴黎最高建筑物。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;上下文中并未提及埃菲尔铁塔的具体地址。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;正式地址为Rue Anatole-France 5号。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 1, \u0026#39;reason\u0026#39;: \u0026#39;该句中的信息与上下文一致，明确提到其建成时间和命名。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;上下文没有提到关于参观人数或其作为技术杰作的具体描述。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观，是法国参观人数第二多的文化景点。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;上下文未提及关于建筑的历史遗产地位的信息。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;上下文中没有提到埃菲尔铁塔的高度或其历史地位。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;上下文没有包含关于观景平台的高度或排名的信息。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。\u0026#39;}, {\u0026#39;attributed\u0026#39;: 0, \u0026#39;reason\u0026#39;: \u0026#39;上下文没有提及天线或科学实验相关的信息。\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。\u0026#39;}] Context Recall: 0.25 Context Entities Recall Context Entities Recall（上下文实体召回率）是一种用于评估检索过程的指标。它的核心思想是比较模型在给定上下文（Context）与真实答案（Ground Truth）中抽取到的实体，并计算Ground Truth中实体的召回率。该指标能够有效评估检索结果对于关键信息的召回率。\nContext Entities Recall的计算公式为：\n\\[ Context\\:Entities\\:Recall = \\frac{上下文中实体 \\cap 真实答案中实体}{真实答案中实体} \\] 上下文中实体：检索到的上下文中实体集合 真实答案中实体：真实答案中实体集合 其中实体抽取主要是使用大模型进行解析，下面是实体抽取的Prompt\n图 6. Context Entities Recall Prompt 下图展示了Context Entites Recall计算过程\n图 7. Context Entities Recall 计算过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 import json from pprint import pprint from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate llm = ChatOpenAI( model=\u0026#34;gpt-4o-mini\u0026#34; ) PROMPT = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Given a text, extract unique entities without repetition. Ensure you consider different forms or mentions of the same entity as a single entity. The output should be a well-formatted JSON instance that conforms to the JSON schema below. As an example, for the schema {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: {{\u0026#34;title\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;a list of strings\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {{\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}}}}, \u0026#34;required\u0026#34;: [\u0026#34;foo\u0026#34;]}} the object {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}} is a well-formatted instance of the schema. The object {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}}}} is not well-formatted. Here is the output JSON schema: {OutputSchema} Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```). Examples: text: \u0026#34;The Eiffel Tower, located in Paris, France, is one of the most iconic landmarks globally. Millions of visitors are attracted to it each year for its breathtaking views of the city. Completed in 1889, it was constructed in time for the 1889 World\\\u0026#39;s Fair.\u0026#34; output: {{\u0026#34;entities\u0026#34;: [\u0026#34;Eiffel Tower\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;France\u0026#34;, \u0026#34;1889\u0026#34;, \u0026#34;World\\\u0026#39;s Fair\u0026#34;]}} text: \u0026#34;The Colosseum in Rome, also known as the Flavian Amphitheatre, stands as a monument to Roman architectural and engineering achievement. Construction began under Emperor Vespasian in AD 70 and was completed by his son Titus in AD 80. It could hold between 50,000 and 80,000 spectators who watched gladiatorial contests and public spectacles.\u0026#34; output: {{\u0026#34;entities\u0026#34;: [\u0026#34;Colosseum\u0026#34;, \u0026#34;Rome\u0026#34;, \u0026#34;Flavian Amphitheatre\u0026#34;, \u0026#34;Vespasian\u0026#34;, \u0026#34;AD 70\u0026#34;, \u0026#34;Titus\u0026#34;, \u0026#34;AD 80\u0026#34;]}} text: \u0026#34;The Great Wall of China, stretching over 21,196 kilometers from east to west, is a marvel of ancient defensive architecture.Built to protect against invasions from the north, its construction started as early as the 7th century BC. Today, it is a UNESCO World Heritage Site and a major tourist attraction.\u0026#34; output: {{\u0026#34;entities\u0026#34;: [\u0026#34;Great Wall of China\u0026#34;, \u0026#34;21,196 kilometers\u0026#34;, \u0026#34;7th century BC\u0026#34;, \u0026#34;UNESCO World Heritage Site\u0026#34;]}} text: \u0026#34;The Apollo 11 mission, which launched on July 16, 1969, marked the first time humans landed on the Moon.Astronauts Neil Armstrong, Buzz Aldrin, and Michael Collins made history, with Armstrong being the first man to step on the lunar surface. This event was a significant milestone in space exploration.\u0026#34; output: {{\u0026#34;entities\u0026#34;: [\u0026#34;Apollo 11 mission\u0026#34;, \u0026#34;July 16, 1969\u0026#34;, \u0026#34;Moon\u0026#34;, \u0026#34;Neil Armstrong\u0026#34;, \u0026#34;Buzz Aldrin\u0026#34;, \u0026#34;Michael Collins\u0026#34;]}} Your actual task: \u0026#34;\u0026#34;\u0026#34; ), ( \u0026#34;human\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your actual task: text: \u0026#34;{Text}\u0026#34; output: \u0026#34;\u0026#34;\u0026#34; ) ] ) def get_v(text): output_schema = \u0026#34;\u0026#34;\u0026#34; {\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;entities\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Entities\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}, \u0026#34;required\u0026#34;: [\u0026#34;entities\u0026#34;]} \u0026#34;\u0026#34;\u0026#34; chain = PROMPT | llm result = chain.invoke( { \u0026#34;OutputSchema\u0026#34;: output_schema, \u0026#34;Text\u0026#34;: text } ) content = result.content if content.startswith(\u0026#34;```json\u0026#34;): content = content.replace(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;) if content.endswith(\u0026#34;```\u0026#34;): content = content.replace(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;) try: content = json.loads(content) except: # verdict = None pass return content classes = [] query = \u0026#34;艾菲尔铁塔在哪里\u0026#34; contexts = [ \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物\u0026#34;, \u0026#34;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#34; ] answer = \u0026#34;\u0026#34;\u0026#34; 埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] （ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物。正式地址为Rue Anatole-France 5号。 埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观[4]，是法国参观人数第二多的文化景点。1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。[5] 埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现，其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。 \u0026#34;\u0026#34;\u0026#34; result_context = get_v(\u0026#34;.\u0026#34;.join(contexts)) pprint(result_context) result_answer = get_v(answer) pprint(result_answer) def compute_score( ground_truth_entities, context_entities ) -\u0026gt; float: num_entities_in_both = len( set(context_entities).intersection(set(ground_truth_entities)) ) return num_entities_in_both / (len(ground_truth_entities) + 1e-8) # for res in result: # classes.append(res[\u0026#34;attributed\u0026#34;]) print(\u0026#34;Context Entites Recall: \u0026#34;, compute_score(result_answer[\u0026#34;entities\u0026#34;], result_context[\u0026#34;entities\u0026#34;])) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 {\u0026#39;entities\u0026#39;: [\u0026#39;埃菲尔铁塔\u0026#39;, \u0026#39;巴黎铁塔\u0026#39;, \u0026#39;法国\u0026#39;, \u0026#39;巴黎\u0026#39;, \u0026#39;塞纳河\u0026#39;, \u0026#39;战神广场\u0026#39;, \u0026#39;居斯塔夫·埃菲尔\u0026#39;, \u0026#39;1889年\u0026#39;, \u0026#39;三百米塔\u0026#39;]} {\u0026#39;entities\u0026#39;: [\u0026#39;埃菲尔铁塔\u0026#39;, \u0026#39;法语\u0026#39;, \u0026#39;巴黎铁塔\u0026#39;, \u0026#39;法国\u0026#39;, \u0026#39;巴黎\u0026#39;, \u0026#39;塞纳河\u0026#39;, \u0026#39;战神广场\u0026#39;, \u0026#39;1889年\u0026#39;, \u0026#39;居斯塔夫·埃菲尔\u0026#39;, \u0026#39;国际土木工程历史古迹\u0026#39;, \u0026#39;1991年\u0026#39;, \u0026#39;世界遗产\u0026#39;, \u0026#39;312米\u0026#39;, \u0026#39;纽约\u0026#39;, \u0026#39;克莱斯勒大楼\u0026#39;, \u0026#39;279.11米\u0026#39;, \u0026#39;欧盟\u0026#39;, \u0026#39;莫斯科\u0026#39;, \u0026#39;奥斯坦金诺电视塔\u0026#39;, \u0026#39;广播电视信号\u0026#39;]} Context Entites Recall: 0.3999999998 Answer Correctness Answer Correctness（答案准确性） 是一种用于评估 RAG（Retrieval-Augmented Generation）应用生成的答案准确性的指标。其目标是衡量模型生成的答案与真实答案（Ground Truth）之间的匹配程度，从而判断模型是否生成了正确且有支持的内容。指标结合了经典的分类评价方法，将生成的答案分为正确识别（TP）、错误识别（FP）和遗漏（FN），帮助RAG应用回答的准确性。\nTP（True Positive，正确识别）： 定义：答案中的语句与真实答案中的语句匹配，且得到了真实答案的明确支持。 作用：识别出模型正确生成的信息。 FP（False Positive，错误识别）： 定义：答案中出现了没有真实答案支持的语句，即错误信息或不相关内容。 作用：检测模型生成的无根据或错误信息。 FN（False Negative，遗漏）： 定义：真实答案中的语句未出现在生成的答案中，即模型漏掉的重要信息。 作用：评估模型在回答时是否遗漏了关键信息。 Answer Correctness 计算公式\n\\[ \\text{Answer Correctness} = \\frac{|\\text{TP}|}{|\\text{TP} + 0.5 * (\\text{FP} + \\text{FN})|} \\]其中大模型分类的Prompt如下所示：\n图 8. Answer Correctness Prompt Answer Correctness 是一个加权的评估指标，同样的根据RAG应用回答分类也可以计算下面的几个指标：\n精准率（Precision）：反映生成的答案中，有多少比例是正确的内容。 \\[ \\text{Precision} = \\frac{|\\text{TP}|}{|\\text{TP} + \\text{FP}|} \\] 召回率（Recall）：反映真实答案中的信息有多少被模型识别并生成。 \\[ \\text{Recall} = \\frac{|\\text{TP}|}{|\\text{TP} + \\text{FN}|} \\] F1分数（F1 Score）：结合了精准率和召回率的平衡指标，作为整体评价。 \\[ F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\] 图 9. Answer Correctness 计算过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 import json from pprint import pprint from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate llm = ChatOpenAI( model=\u0026#34;gpt-4o-mini\u0026#34; ) PROMPT = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Given a ground truth and an answer statements, analyze each statement and classify them in one of the following categories: - TP (true positive): statements that are present in answer that are also directly supported by the one or more statements in ground truth, - FP (false positive): statements present in the answer but not directly supported by any statement in ground truth, - FN (false negative): statements found in the ground truth but not present in answer. Each statement can only belong to one of the categories. Provide a reason for each classification. The output should be a well-formatted JSON instance that conforms to the JSON schema below. As an example, for the schema {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: {{\u0026#34;title\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;a list of strings\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {{\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}}}}, \u0026#34;required\u0026#34;: [\u0026#34;foo\u0026#34;]}} the object {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}} is a well-formatted instance of the schema. The object {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}}}} is not well-formatted. Here is the output JSON schema: {OutputSchema} Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```). Examples: question: \u0026#34;What powers the sun and what is its primary function?\u0026#34; answer: [\u0026#34;The sun is powered by nuclear fission, similar to nuclear reactors on Earth.\u0026#34;, \u0026#34;The primary function of the sun is to provide light to the solar system.\u0026#34;] ground_truth: [\u0026#34;The sun is powered by nuclear fusion, where hydrogen atoms fuse to form helium.\u0026#34;, \u0026#34;This fusion process in the sun\\\u0026#39;s core releases a tremendous amount of energy.\u0026#34;, \u0026#34;The energy from the sun provides heat and light, which are essential for life on Earth.\u0026#34;, \u0026#34;The sun\\\u0026#39;s light plays a critical role in Earth\\\u0026#39;s climate system.\u0026#34;, \u0026#34;Sunlight helps to drive the weather and ocean currents.\u0026#34;] classification: {{\u0026#34;TP\u0026#34;: [{{\u0026#34;statement\u0026#34;: \u0026#34;The primary function of the sun is to provide light to the solar system.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This statement is somewhat supported by the ground truth mentioning the sun providing light and its roles, though it focuses more broadly on the sun\\\u0026#39;s energy.\u0026#34;}}], \u0026#34;FP\u0026#34;: [{{\u0026#34;statement\u0026#34;: \u0026#34;The sun is powered by nuclear fission, similar to nuclear reactors on Earth.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This statement is incorrect and contradicts the ground truth which states that the sun is powered by nuclear fusion.\u0026#34;}}], \u0026#34;FN\u0026#34;: [{{\u0026#34;statement\u0026#34;: \u0026#34;The sun is powered by nuclear fusion, where hydrogen atoms fuse to form helium.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This accurate description of the sun’s power source is not included in the answer.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;This fusion process in the sun\\\u0026#39;s core releases a tremendous amount of energy.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This process and its significance are not mentioned in the answer.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;The energy from the sun provides heat and light, which are essential for life on Earth.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;The answer only mentions light, omitting the essential aspects of heat and its necessity for life, which the ground truth covers.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;The sun\\\u0026#39;s light plays a critical role in Earth\\\u0026#39;s climate system.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This broader impact of the sun’s light on Earth\\\u0026#39;s climate system is not addressed in the answer.\u0026#34;}}, {{\u0026#34;statement\u0026#34;: \u0026#34;Sunlight helps to drive the weather and ocean currents.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;The effect of sunlight on weather patterns and ocean currents is omitted in the answer.\u0026#34;}}]}} question: \u0026#34;What is the boiling point of water?\u0026#34; answer: [\u0026#34;The boiling point of water is 100 degrees Celsius at sea level\u0026#34;] ground_truth: [\u0026#34;The boiling point of water is 100 degrees Celsius (212 degrees Fahrenheit) at sea level.\u0026#34;, \u0026#34;The boiling point of water can change with altitude.\u0026#34;] classification: {{\u0026#34;TP\u0026#34;: [{{\u0026#34;statement\u0026#34;: \u0026#34;The boiling point of water is 100 degrees Celsius at sea level\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This statement is directly supported by the ground truth which specifies the boiling point of water as 100 degrees Celsius at sea level.\u0026#34;}}], \u0026#34;FP\u0026#34;: [], \u0026#34;FN\u0026#34;: [{{\u0026#34;statement\u0026#34;: \u0026#34;The boiling point of water can change with altitude.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;This additional information about how the boiling point of water can vary with altitude is not mentioned in the answer.\u0026#34;}}]}} Your actual task: \u0026#34;\u0026#34;\u0026#34; ), ( \u0026#34;human\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your actual task: question:\u0026#34;{Query}\u0026#34; answer:\u0026#34;{Answer}\u0026#34; ground_truth:\u0026#34;{GroundTruth}\u0026#34; classification: \u0026#34;\u0026#34;\u0026#34; ) ] ) def get_v(query, context, answer, ground_truth): output_schema = \u0026#34;\u0026#34;\u0026#34; {\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;TP\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Tp\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;}}, \u0026#34;FP\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Fp\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;}}, \u0026#34;FN\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Fn\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;}}}, \u0026#34;required\u0026#34;: [\u0026#34;TP\u0026#34;, \u0026#34;FP\u0026#34;, \u0026#34;FN\u0026#34;]} \u0026#34;\u0026#34;\u0026#34; chain = PROMPT | llm result = chain.invoke( { \u0026#34;OutputSchema\u0026#34;: output_schema, \u0026#34;Query\u0026#34;: query, \u0026#34;Context\u0026#34;: context, \u0026#34;Answer\u0026#34;: answer, \u0026#34;GroundTruth\u0026#34;: ground_truth } ) content = result.content if content.startswith(\u0026#34;```json\u0026#34;): content = content.replace(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;) if content.endswith(\u0026#34;```\u0026#34;): content = content.replace(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;) try: content = json.loads(content) except: # verdict = None pass return content classes = [] query = \u0026#34;介绍下艾菲尔铁塔\u0026#34; contexts = [ \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物\u0026#34;, \u0026#34;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#34; ] ground_truth = \u0026#34;\u0026#34;\u0026#34; 埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] （ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物。正式地址为Rue Anatole-France 5号。 埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观[4]，是法国参观人数第二多的文化景点。1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。[5] 埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现，其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。 \u0026#34;\u0026#34;\u0026#34; answer = \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）位于法国巴黎第七区\u0026#34; result = get_v(query, \u0026#34;.\u0026#34;.join(contexts), answer, ground_truth) pprint(result) def compute_statement_presence( prediction ) -\u0026gt; float: tp = len(prediction[\u0026#34;TP\u0026#34;]) fp = len(prediction[\u0026#34;FP\u0026#34;]) fn = len(prediction[\u0026#34;FN\u0026#34;]) score = tp / (tp + 0.5 * (fp + fn)) if tp \u0026gt; 0 else 0 return score print(\u0026#34;Answer Correctness: \u0026#34;, compute_statement_presence(result)) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 {\u0026#39;FN\u0026#39;: [{\u0026#39;reason\u0026#39;: \u0026#39;This detailed description of the Eiffel Tower, including \u0026#39; \u0026#39;its material, cultural significance, and formal address, \u0026#39; \u0026#39;is missing from the answer.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一，巴黎城市地标之一，巴黎最高建筑物。正式地址为Rue \u0026#39; \u0026#39;Anatole-France 5号。\u0026#39;}, {\u0026#39;reason\u0026#39;: \u0026#39;The construction year and original name of the Eiffel \u0026#39; \u0026#39;Tower are not mentioned in the answer.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#39;}, {\u0026#39;reason\u0026#39;: \u0026#39;The answer does not include any information about its \u0026#39; \u0026#39;status as a historical engineering marvel or visitor \u0026#39; \u0026#39;statistics.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观，是法国参观人数第二多的文化景点。\u0026#39;}, {\u0026#39;reason\u0026#39;: \u0026#39;This important historical recognition of the Eiffel Tower \u0026#39; \u0026#39;is absent in the answer.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。\u0026#39;}, {\u0026#39;reason\u0026#39;: \u0026#39;The height of the Eiffel Tower and its ranking among \u0026#39; \u0026#39;man-made structures are not mentioned in the answer.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现。\u0026#39;}, {\u0026#39;reason\u0026#39;: \u0026#39;Information about the viewing platform and its \u0026#39; \u0026#39;significance is missing from the answer.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。\u0026#39;}, {\u0026#39;reason\u0026#39;: \u0026#39;The mention of the antennas and their functions is not \u0026#39; \u0026#39;covered in the answer.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。\u0026#39;}], \u0026#39;FP\u0026#39;: [], \u0026#39;TP\u0026#39;: [{\u0026#39;reason\u0026#39;: \u0026#39;This statement is directly supported by the ground truth, \u0026#39; \u0026#39;which states that the Eiffel Tower is located in the 7th \u0026#39; \u0026#39;arrondissement of Paris.\u0026#39;, \u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔位于法国巴黎第七区\u0026#39;}]} Answer Correctness: 0.2222222222222222 Answer Semantic Similarity Answer Semantic Similarity（答案的语义相似性）是用来评估生成答案与原始事实在语义上相近程度的关键指标。通过计算生成答案与基本事实的嵌入向量之间的余弦相似度，可以量化这种相似性。如果设定了一个特定的阈值，根据计算结果，得分会被转换为二进制值；即，当余弦相似度大于或等于该阈值时，值为1，否则为0。\n\\[ Answer\\:Semantic\\:Similarity = \\cos(\\hat{v}_{\\text{answer}}, \\hat{v}_{\\text{fact}}) \\] \\(\\hat{v}_{\\text{answer}}\\)：表示生成答案的嵌入向量。 \\(\\hat{v}_{\\text{fact}}\\)：表示基本事实的嵌入向量。 阈值：用于将相似度得分转换为二进制判断的临界值。 图 9. Answer Semantic Similarity 计算过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import numpy as np from langchain_openai import OpenAIEmbeddings embeddings = OpenAIEmbeddings( model=\u0026#34;text-embedding-3-small\u0026#34;, ) query = \u0026#34;介绍下艾菲尔铁塔\u0026#34; ground_truth = \u0026#34;\u0026#34;\u0026#34; 埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] （ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物。正式地址为Rue Anatole-France 5号。 埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观[4]，是法国参观人数第二多的文化景点。1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。[5] 埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现，其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。 \u0026#34;\u0026#34;\u0026#34; answer = \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）位于法国巴黎第七区\u0026#34; def compute_similarity( answer, ground_truth, embeddings ) -\u0026gt; float: embedding_1 = np.array(embeddings.embed_query(ground_truth)) embedding_2 = np.array(embeddings.embed_query(answer)) # Normalization factors of the above embeddings norms_1 = np.linalg.norm(embedding_1, keepdims=True) norms_2 = np.linalg.norm(embedding_2, keepdims=True) embedding_1_normalized = embedding_1 / norms_1 embedding_2_normalized = embedding_2 / norms_2 similarity = embedding_1_normalized @ embedding_2_normalized.T score = similarity.flatten() return score print(\u0026#34;Answer Correctness: \u0026#34;, compute_similarity(answer, ground_truth, embeddings)) 1 Answer Correctness: [0.70861593] Answer Fathfulness Faithfulness（忠实性）指标用于衡量生成答案与给定上下文之间的事实一致性。该指标通过生成答案和检索到的上下文进行计算，其结果被缩放至 (0,1) 区间，数值越高表示忠实性越强。\n如果生成的答案中所做出的所有陈述都能够从给定的上下文中推导出来，则视为忠实。在计算忠实性时，首先从生成的答案中识别出一组陈述，然后将每一个陈述与给定的上下文进行逐一核对，判断其是否可以从上下文中推导出来。忠实性得分的计算公式如下： \\[ Faithfulness score = \\frac{可以推导出的陈述数量}{陈述总数量} \\] 可以推导出的陈述数量：指生成答案中，与给定上下文核对后确认可以推导出的陈述数量。 陈述总数量：指从生成的答案中识别出的全部陈述数量。 其中陈述总数量是通过大模型进行拆分，下面是根据RAG输出的答案生成陈述的Prompt\n图 10. Answer To Statements Prompt 可以推导出的陈述数量也是通过大模型进行判断，根据上述过程生成的陈述以及检索到的上下文，判断模型生成的答案是否可以在上下文中找到依据，下面给定上下文判断是否可以推导出的陈述的Prompt\n图 11. Answer Statements Fathfulness Prompt 下面是Answer Fathfulness的计算过程\n图 12. Answer Fathfulness 计算过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 import json from pprint import pprint from langchain_openai import ChatOpenAI from pysbd import Segmenter from langchain_core.prompts import ChatPromptTemplate llm = ChatOpenAI( model=\u0026#34;gpt-4o-mini\u0026#34; ) STATEMENTS_PROMPT = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under \u0026#39;sentences\u0026#39; and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON. The output should be a well-formatted JSON instance that conforms to the JSON schema below. As an example, for the schema {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: {{\u0026#34;title\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;a list of strings\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {{\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}}}}, \u0026#34;required\u0026#34;: [\u0026#34;foo\u0026#34;]}} the object {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}} is a well-formatted instance of the schema. The object {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}}}} is not well-formatted. Here is the output JSON schema: {OutputSchema} Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```). Examples: question: \u0026#34;Who was Albert Einstein and what is he best known for?\u0026#34; answer: \u0026#34;He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\u0026#34; sentences: \u0026#34;0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. 1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\u0026#34; analysis: [{{\u0026#34;sentence_index\u0026#34;: 0, \u0026#34;simpler_statements\u0026#34;: [\u0026#34;Albert Einstein was a German-born theoretical physicist.\u0026#34;, \u0026#34;Albert Einstein is recognized as one of the greatest and most influential physicists of all time.\u0026#34;]}}, {{\u0026#34;sentence_index\u0026#34;: 1, \u0026#34;simpler_statements\u0026#34;: [\u0026#34;Albert Einstein was best known for developing the theory of relativity.\u0026#34;, \u0026#34;Albert Einstein also made important contributions to the development of the theory of quantum mechanics.\u0026#34;]}}] Your actual task: \u0026#34;\u0026#34;\u0026#34; ), ( \u0026#34;human\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your actual task: question:\u0026#34;{Query}\u0026#34; answer:\u0026#34;{Answer}\u0026#34; sentences:\u0026#34;{Sentences}\u0026#34; analysis: \u0026#34;\u0026#34;\u0026#34; ) ] ) def get_statements(query, answer, sentences): output_schema = \u0026#34;\u0026#34;\u0026#34; {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;$ref\u0026#34;: \u0026#34;#/definitions/Statements\u0026#34;}, \u0026#34;definitions\u0026#34;: {\u0026#34;Statements\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Statements\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;sentence_index\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Sentence Index\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Index of the sentence from the statement list\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, \u0026#34;simpler_statements\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Simpler Statements\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;the simpler statements\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}, \u0026#34;required\u0026#34;: [\u0026#34;sentence_index\u0026#34;, \u0026#34;simpler_statements\u0026#34;]}}} \u0026#34;\u0026#34;\u0026#34; chain = STATEMENTS_PROMPT | llm result = chain.invoke( { \u0026#34;OutputSchema\u0026#34;: output_schema, \u0026#34;Query\u0026#34;: query, \u0026#34;Answer\u0026#34;: answer, \u0026#34;Sentences\u0026#34;: sentences } ) content = result.content if content.startswith(\u0026#34;```json\u0026#34;): content = content.replace(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;) if content.endswith(\u0026#34;```\u0026#34;): content = content.replace(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;) try: content = json.loads(content) except: # verdict = None pass return content classes = [] query = \u0026#34;介绍下艾菲尔铁塔\u0026#34; contexts = [ \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物\u0026#34;, \u0026#34;埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。\u0026#34; ] ground_truth = \u0026#34;\u0026#34;\u0026#34; 埃菲尔铁塔（法语：Tour Eiffel，/ˈaɪfəl/ [tuʁ‿ɛfɛl] （ⓘ），也常称为巴黎铁塔）是位于法国巴黎第七区、塞纳河畔战神广场的铁制镂空塔，世界著名建筑，也是法国文化象征之一[3]，巴黎城市地标之一，巴黎最高建筑物。正式地址为Rue Anatole-France 5号。 埃菲尔铁塔建成于1889年，初名为“三百米塔”，后得名自其设计师居斯塔夫·埃菲尔。铁塔是世界建筑史上的技术杰作，也是世界上最多人付费参观的名胜古迹，这个为了世界博览会而落成的金属建筑，2011年约有698万人参观[4]，是法国参观人数第二多的文化景点。1986年美国土木工程师协会将该建筑列入国际土木工程历史古迹，1991年，埃菲尔铁塔连同巴黎塞纳河沿岸整座被列入世界遗产。[5] 埃菲尔铁塔以312米的高度，占据世界最高人造建筑的位置长达四十年，直到纽约克莱斯勒大楼的出现，其位于279.11米处的观景平台是欧盟范围内公众能够抵达的最高的观景台，在全欧洲范围内仅次于莫斯科的奥斯坦金诺电视塔。铁塔的总高度曾通过安装天线而多次提高。这些天线曾被用于许多科学实验，现在主要用于发射广播电视信号。 \u0026#34;\u0026#34;\u0026#34; answer = \u0026#34;埃菲尔铁塔（也常称为巴黎铁塔）位于法国巴黎第七区\u0026#34; seg = Segmenter(language=\u0026#34;zh\u0026#34;) statements = seg.segment(answer) result = get_statements(query, answer, statements) pprint(result) FATHFULNESS_PROMPT = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context. The output should be a well-formatted JSON instance that conforms to the JSON schema below. As an example, for the schema {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: {{\u0026#34;title\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;a list of strings\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {{\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}}}}}}, \u0026#34;required\u0026#34;: [\u0026#34;foo\u0026#34;]}} the object {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}} is a well-formatted instance of the schema. The object {{\u0026#34;properties\u0026#34;: {{\u0026#34;foo\u0026#34;: [\u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;]}}}} is not well-formatted. Here is the output JSON schema: {OutputSchema} Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```). Examples: context: \u0026#34;John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.\u0026#34; statements: [\u0026#34;John is majoring in Biology.\u0026#34;, \u0026#34;John is taking a course on Artificial Intelligence.\u0026#34;, \u0026#34;John is a dedicated student.\u0026#34;, \u0026#34;John has a part-time job.\u0026#34;] answer: [{{\u0026#34;statement\u0026#34;: \u0026#34;John is majoring in Biology.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;John\\\u0026#39;s major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\u0026#34;, \u0026#34;verdict\u0026#34;: 0}}, {{\u0026#34;statement\u0026#34;: \u0026#34;John is taking a course on Artificial Intelligence.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.\u0026#34;, \u0026#34;verdict\u0026#34;: 0}}, {{\u0026#34;statement\u0026#34;: \u0026#34;John is a dedicated student.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.\u0026#34;, \u0026#34;verdict\u0026#34;: 1}}, {{\u0026#34;statement\u0026#34;: \u0026#34;John has a part-time job.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;There is no information given in the context about John having a part-time job.\u0026#34;, \u0026#34;verdict\u0026#34;: 0}}] context: \u0026#34;Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.\u0026#34; statements: [\u0026#34;Albert Einstein was a genius.\u0026#34;] answer: [{{\u0026#34;statement\u0026#34;: \u0026#34;Albert Einstein was a genius.\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;The context and statement are unrelated\u0026#34;, \u0026#34;verdict\u0026#34;: 0}}] Your actual task: \u0026#34;\u0026#34;\u0026#34; ), ( \u0026#34;human\u0026#34;, \u0026#34;\u0026#34;\u0026#34; Your actual task: context:\u0026#34;{Context}\u0026#34; statements:\u0026#34;{Statements}\u0026#34; answer: \u0026#34;\u0026#34;\u0026#34; ) ] ) def get_fathfullness_results(context, statements): output_schema = \u0026#34;\u0026#34;\u0026#34; {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;$ref\u0026#34;: \u0026#34;#/definitions/StatementFaithfulnessAnswer\u0026#34;}, \u0026#34;definitions\u0026#34;: {\u0026#34;StatementFaithfulnessAnswer\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;StatementFaithfulnessAnswer\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: {\u0026#34;statement\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Statement\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;the original statement, word-by-word\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;reason\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Reason\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;the reason of the verdict\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;verdict\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Verdict\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;the verdict(0/1) of the faithfulness.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}}, \u0026#34;required\u0026#34;: [\u0026#34;statement\u0026#34;, \u0026#34;reason\u0026#34;, \u0026#34;verdict\u0026#34;]}}} \u0026#34;\u0026#34;\u0026#34; chain = FATHFULNESS_PROMPT | llm result = chain.invoke( { \u0026#34;OutputSchema\u0026#34;: output_schema, \u0026#34;Context\u0026#34;: context, \u0026#34;Statements\u0026#34;: statements } ) content = result.content if content.startswith(\u0026#34;```json\u0026#34;): content = content.replace(\u0026#34;```json\u0026#34;, \u0026#34;\u0026#34;) if content.endswith(\u0026#34;```\u0026#34;): content = content.replace(\u0026#34;```\u0026#34;, \u0026#34;\u0026#34;) try: content = json.loads(content) except: # verdict = None pass return content results = get_fathfullness_results(\u0026#34;.\u0026#34;.join(contexts), statements) print(results) verdicts = [_[\u0026#34;verdict\u0026#34;] for _ in results] print(\u0026#34;Answer Fathfulness: \u0026#34;, sum(verdicts) / len(verdicts)) 1 2 3 4 [{\u0026#39;sentence_index\u0026#39;: 0, \u0026#39;simpler_statements\u0026#39;: [\u0026#39;埃菲尔铁塔也常称为巴黎铁塔。\u0026#39;, \u0026#39;埃菲尔铁塔位于法国巴黎第七区。\u0026#39;]}] [{\u0026#39;statement\u0026#39;: \u0026#39;埃菲尔铁塔（也常称为巴黎铁塔）位于法国巴黎第七区\u0026#39;, \u0026#39;reason\u0026#39;: \u0026#39;上下文明确提到埃菲尔铁塔位于法国巴黎第七区，因此该陈述可以直接推断。\u0026#39;, \u0026#39;verdict\u0026#39;: 1}] Answer Fathfulness: 1.0 讨论 在本文中，我们探讨了基于大型语言模型的RAG应用自动化评估方法，并详细阐述了每个评估指标的提示设计及其Python实现方式。通过本篇文章，我们不仅理解了如何利用大型语言模型进行评估，还可以根据自身的业务场景制定相应的评估指标。\n值得注意的是，在上述评估指标的计算过程中，我们使用了几个关键要素，即Query、Context、Answer和Ground Truth。其中，Query、Context和Answer是RAG应用的输入、中间变量和生成结果，这些要素相对容易获取。然而，获取Ground Truth通常较为困难。在一般情况下，Ground Truth可通过人工或专家标注获得，但这种方法往往需要大量的人力资源。\n如果我们能够解决自动生成Ground Truth的过程，那么整个评估流程将会实现自动化。在下一篇文章中，我们将深入探讨如何基于文档自动生成高质量的问答数据。\n引用 Yu H, Gan A, Zhang K, et al. Evaluation of Retrieval-Augmented Generation: A Survey[J]. arXiv preprint arXiv:2405.07437, 2024. https://research.trychroma.com/evaluating-chunking https://github.com/explodinggradients/ragas ","date":"2024-09-29T17:17:35+08:00","permalink":"https://blackdzs.github.io/p/rag%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97%E4%BA%8C%E5%A6%82%E4%BD%95%E8%AF%84%E4%BC%B0%E4%B8%8E%E4%BC%98%E5%8C%96rag%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD/","title":"RAG应用开发指南（二）：如何评估与优化RAG应用性能"},{"content":"1、介绍 在大模型的使用过程中，我们会发现大模型在面对一些无法回答的问题时会自信的给出错误的答案，即模型的“幻觉”(Hallucinations)现象。这种现象主要源于大模型的训练方式和其内在的工作机制。大模型尤其是基于Transformer架构的预训练模型，是通过在大规模数据集上进行无监督学习，学习到语言的统计规律和模式。然而，这种学习方式并不能确保模型完全理解其生成内容的逻辑和真实性。因此大模型在面对实时，专有的以及特定领域的提问时的回答会经常出现事实性错误。\n在实际应用中，特别是在医疗、金融、工业等对准确性要求极高的领域，幻觉现象可能会产生严重后果。比如：\n医疗模型给出错误的诊断和用药信息：这种错误可能会对患者的生命安全造成威胁，错误的诊断可能导致错过最佳治疗时机，错误的用药信息可能导致药物不良反应甚至死亡。\n工业模型给出错误的分析和建议：在工业生产中，错误的分析和建议可能导致生产效率下降、产品质量问题、设备损坏或安全事故发生，造成巨大的经济损失和安全隐患。\n在2020年，Meta AILewis, Patrick, et al.2020 提出来使用信息检索的方式来辅助大模型进行内容生成，显著提高了在大模型在知识密集的任务中的生成效果。这篇论文提出了一个完整的RAG框架，展示了如何在多个知识密集型NLP任务中有效地利用RAG，如问答、对话生成和文档摘要。\nTable 1: RAG性能对比 从Table1可以看到在四个测试数据集上，使用RAG相比只靠模型能力(Closed Book)带来了显著的性能提升。\n2、RAG工作原理 RAG（Retrieval-Augmented Generation）的核心思想是在生成答案之前，先从一个大型知识库或文档集合中检索相关信息，并将这些信息作为额外输入提供给大模型，从而提高生成内容的质量。这种方法将大模型的知识和推理能力进行分离，因此在处理实时的、专有的以及特定领域的问题时，大模型可以借助外部知识来填补自身知识的不足，同时利用其推理能力生成正确的答案。\n在实际应用中，RAG主要分为两个阶段：向量数据库构建（离线）阶段和检索增强生成（在线）阶段。\n2.1 向量数据库 向量数据库是RAG应用的基础，这个数据库作为外部知识库，包含了RAG应用所需的所有的额外信息。向量数据库的质量直接决定了RAG应用的性能下限，一个高质量的向量数据库能够在使用更少的token的情况下，提供回答用户问题所需的更多背景信息。因此，在实际业务场景中，高质量的向量数据库不仅能够显著提升应用的准确性，还能有效降低推理成本。\n2.1.1 使用LangChain构建向量数据库的流程 准备 首先，需要安装 LangChain 以及其他相关库，如向量数据库 langchain-chroma, OpenAI模型 langchain-openai\n1 pip install -qU \u0026#34;langchain-chroma\u0026#34; \u0026#34;langchain-openai\u0026#34; 设置OpenAI API key\n1 2 3 4 import os # os.environ[\u0026#39;OPENAI_API_BASE\u0026#39;] = \u0026#39;\u0026lt;OPENAI API BASE\u0026gt;\u0026#39; os.environ[\u0026#39;OPENAI_API_KEY\u0026#39;] = \u0026#39;\u0026lt;YOUR OPENAI API KEY\u0026gt;\u0026#39; 文本解析 在这个示例中，我们使用WebBaseLoader加载本篇博客，然后使用BeautifulSoup提取HTML中内容转化为文本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import bs4 from langchain_community.document_loaders import WebBaseLoader loader = WebBaseLoader( web_paths=( \u0026#34;https://blackdzs.github.io/posts/%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BArag%E5%BA%94%E7%94%A8/\u0026#34;, ), bs_kwargs=dict( parse_only=bs4.SoupStrainer( class_=(\u0026#34;post-content\u0026#34;, \u0026#34;post-title\u0026#34;, \u0026#34;post-header\u0026#34;) ) ), ) documents = loader.load() print(documents[0].page_content[:21]) 1 Home » Posts【RAG应用开发】 这段代码提取了原始HTML中的post-content,post-title和post-header三部分的内容并保存为Langchain Document格式，我们可以使用page_content属性访问到解析后的文本。\n文档分块 我们提到，高质量的向量数据库应在使用少量token的情况下包含更多信息，而文档分块（chunking）的主要目的是将文档内容进行合理分割，将同一概念下的相关内容集中在同一个chunk中。这样，在进行检索时，只需选择最相关的chunk即可，从而在获取相关信息的同时有效减少了token的数量。\n1 2 3 4 5 6 # 导入必要的库 from langchain.text_splitter import RecursiveCharacterTextSplitter # 使用RecursiveCharacterTextSplitter将较长的文本拆分成更小的块 text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100) split_documents = text_splitter.split_documents(documents) 在上面的示例中我们使用RecursiveCharacterTextSplitter文档分割方法\n构建向量数据库 在这个示例中我们使用Chroma作为向量数据库\n1 2 3 4 5 from langchain_openai import OpenAIEmbeddings from langchain_chroma import Chroma embeddings = OpenAIEmbeddings() vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings) RAG 知识库构建过程 向量数据库构建阶段的核心任务是将多种来源的非结构化数据经过处理和编码，转化为一个结构化且易于检索的知识库。这个知识库将在 RAG 系统中作为后续检索和生成答案的重要基础。\n2.2 检索增强生成(RAG) 构建检索器 在向量数据库构建完成后我们就可以在询问大模型问题时进行使用了，在Langchain中构建的任何vectorstore都可以使用as_retriever转化为检索器，同时可以设置检索器的参数，如检索文档时向量计算方法search_type, 返回文档数量k。 1 2 3 retriever = vectorstore.as_retriever(search_type=\u0026#34;similarity\u0026#34;, search_kwargs={\u0026#34;k\u0026#34;: 3}) retrieved_docs = retriever.invoke(\u0026#34;什么是RAG\u0026#34;) print(len(retrieved_docs)) 1 3 生成答案 接下来是根据检索器检索到的内容生成回答，我们需要将retrieved_docs 和 question构造成模型输入的Prompt, 然后输入到模型中生成回答。 1 2 3 4 5 6 from langchain_openai import ChatOpenAI from langchain import hub prompt = hub.pull(\u0026#34;rlm/rag-prompt\u0026#34;) llm = ChatOpenAI(model=\u0026#34;gpt-4o-mini\u0026#34;) print(prompt) 1 input_variables=[\u0026#39;context\u0026#39;, \u0026#39;question\u0026#39;] input_types={} partial_variables={} metadata={\u0026#39;lc_hub_owner\u0026#39;: \u0026#39;rlm\u0026#39;, \u0026#39;lc_hub_repo\u0026#39;: \u0026#39;rag-prompt\u0026#39;, \u0026#39;lc_hub_commit_hash\u0026#39;: \u0026#39;50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e\u0026#39;} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\u0026#39;context\u0026#39;, \u0026#39;question\u0026#39;], input_types={}, partial_variables={}, template=\u0026#34;You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\u0026#39;t know the answer, just say that you don\u0026#39;t know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\u0026#34;), additional_kwargs={})] 其中template内容为：\n1 2 3 4 5 You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\u0026#39;t know the answer, just say that you don\u0026#39;t know. Use three sentences maximum and keep the answer concise. Question: {question} Context: {context} Answer: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from langchain_core.output_parsers import StrOutputParser from langchain_core.runnables import RunnablePassthrough def format_docs(docs): res = \u0026#34;\\n\\n\u0026#34;.join(doc.page_content for doc in docs) print(res) return res rag_chain = ( {\u0026#34;context\u0026#34;: retriever | format_docs, \u0026#34;question\u0026#34;: RunnablePassthrough()} | prompt | llm | StrOutputParser() ) for chunk in rag_chain.stream(\u0026#34;什么是RAG\u0026#34;): print(chunk, end=\u0026#34;\u0026#34;, flush=True) 下图为检索增强生成阶段的主要流程：\nRAG 检索增强生成过程 在本篇文章中我们介绍了RAG的工作原理与基于Langchain实现简单的RAG应用，在下一篇文章中我们讨论如何评估RAG应用\n参考 Lewis, Patrick, et al. \u0026ldquo;Retrieval-augmented generation for knowledge-intensive nlp tasks.\u0026rdquo; Advances in Neural Information Processing Systems 33 (2020): 9459-9474. https://python.langchain.com/docs/tutorials/rag/#indexing-store ","date":"2024-09-25T19:47:59+08:00","permalink":"https://blackdzs.github.io/p/rag%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97%E4%B8%80%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90rag%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/","title":"RAG应用开发指南（一）：深入解析RAG原理与实现"}]